# Django ORM Enhancement Package
# Custom management commands and migration utilities

import os
import subprocess
from pathlib import Path
from typing import List, Dict, Any

class DjangoORMManager:
    """Enhanced Django ORM manager with custom migration commands."""
    
    def __init__(self, project_name: str):
        self.project_name = project_name
        self.manage_py = Path("manage.py")
        
    def create_custom_migration_commands(self) -> Dict[str, str]:
        """Create custom Django management commands for enhanced ORM operations."""
        
        return {
            # Custom migration command for data migrations
            f'{self.project_name}/management/__init__.py': '',
            f'{self.project_name}/management/commands/__init__.py': '',
            
            f'{self.project_name}/management/commands/create_data_migration.py': '''"""
Custom management command to create data migration with template.
"""
from django.core.management.base import BaseCommand, CommandError
from django.core.management import call_command
from django.apps import apps
import os


class Command(BaseCommand):
    help = 'Create a data migration with enhanced template'

    def add_arguments(self, parser):
        parser.add_argument('app_label', type=str, help='App label for the migration')
        parser.add_argument('migration_name', type=str, help='Name of the migration')
        parser.add_argument(
            '--model',
            type=str,
            help='Model name to include in migration template'
        )
        parser.add_argument(
            '--operation',
            choices=['create', 'update', 'delete', 'custom'],
            default='custom',
            help='Type of data operation'
        )

    def handle(self, *args, **options):
        app_label = options['app_label']
        migration_name = options['migration_name']
        model_name = options.get('model', '')
        operation = options['operation']

        # Validate app exists
        try:
            apps.get_app_config(app_label)
        except LookupError:
            raise CommandError(f'App "{app_label}" not found')

        # Create empty migration
        call_command('makemigrations', app_label, '--empty', '--name', migration_name)

        # Get the migration file path
        migrations_dir = apps.get_app_config(app_label).path + '/migrations'
        migration_files = [f for f in os.listdir(migrations_dir) 
                          if f.endswith('.py') and migration_name in f]
        
        if not migration_files:
            raise CommandError('Migration file not created')

        migration_file = os.path.join(migrations_dir, migration_files[0])

        # Generate migration template based on operation type
        template = self.get_migration_template(operation, model_name, app_label)

        # Replace the empty migration with our template
        with open(migration_file, 'w') as f:
            f.write(template)

        self.stdout.write(
            self.style.SUCCESS(
                f'Created data migration: {migration_file}\\n'
                f'Operation type: {operation}\\n'
                f'Remember to implement the forward and reverse operations!'
            )
        )

    def get_migration_template(self, operation: str, model_name: str, app_label: str) -> str:
        """Generate migration template based on operation type."""
        
        templates = {
            'create': f'''# Generated by Re-Shell Django ORM Manager
from django.db import migrations
from django.conf import settings


def create_{model_name.lower()}_data(apps, schema_editor):
    """Forward data migration - create {model_name} data."""
    {model_name} = apps.get_model('{app_label}', '{model_name}')
    
    # TODO: Implement data creation logic
    # Example:
    # {model_name}.objects.bulk_create([
    #     {model_name}(field1='value1', field2='value2'),
    #     # Add more instances as needed
    # ])
    pass


def reverse_{model_name.lower()}_data(apps, schema_editor):
    """Reverse data migration - remove {model_name} data."""
    {model_name} = apps.get_model('{app_label}', '{model_name}')
    
    # TODO: Implement data removal logic
    # Example:
    # {model_name}.objects.filter(field1='value1').delete()
    pass


class Migration(migrations.Migration):
    dependencies = [
        # TODO: Add dependency to the latest migration in this app
        ('{app_label}', '0001_initial'),
    ]

    operations = [
        migrations.RunPython(
            create_{model_name.lower()}_data,
            reverse_{model_name.lower()}_data,
        ),
    ]
''',
            
            'update': f'''# Generated by Re-Shell Django ORM Manager
from django.db import migrations


def update_{model_name.lower()}_data(apps, schema_editor):
    """Forward data migration - update {model_name} data."""
    {model_name} = apps.get_model('{app_label}', '{model_name}')
    
    # TODO: Implement data update logic
    # Example:
    # {model_name}.objects.filter(old_field='old_value').update(
    #     new_field='new_value'
    # )
    pass


def reverse_{model_name.lower()}_data(apps, schema_editor):
    """Reverse data migration - revert {model_name} data updates."""
    {model_name} = apps.get_model('{app_label}', '{model_name}')
    
    # TODO: Implement data reversion logic
    # Example:
    # {model_name}.objects.filter(new_field='new_value').update(
    #     old_field='old_value'
    # )
    pass


class Migration(migrations.Migration):
    dependencies = [
        ('{app_label}', '0001_initial'),
    ]

    operations = [
        migrations.RunPython(
            update_{model_name.lower()}_data,
            reverse_{model_name.lower()}_data,
        ),
    ]
''',
            
            'custom': f'''# Generated by Re-Shell Django ORM Manager
from django.db import migrations


def forward_migration(apps, schema_editor):
    """Forward data migration logic."""
    # TODO: Implement forward migration logic
    # Get models like this:
    # Model = apps.get_model('{app_label}', 'ModelName')
    pass


def reverse_migration(apps, schema_editor):
    """Reverse data migration logic."""
    # TODO: Implement reverse migration logic
    pass


class Migration(migrations.Migration):
    dependencies = [
        ('{app_label}', '0001_initial'),
    ]

    operations = [
        migrations.RunPython(
            forward_migration,
            reverse_migration,
        ),
    ]
''',
        }

        return templates.get(operation, templates['custom'])
''',

            f'{self.project_name}/management/commands/reset_migrations.py': '''"""
Custom management command to reset migrations for development.
"""
from django.core.management.base import BaseCommand, CommandError
from django.core.management import call_command
from django.apps import apps
from django.db import connection
import os
import shutil


class Command(BaseCommand):
    help = 'Reset migrations for specified apps (DEVELOPMENT ONLY)'

    def add_arguments(self, parser):
        parser.add_argument(
            'app_labels',
            nargs='+',
            type=str,
            help='App labels to reset migrations for'
        )
        parser.add_argument(
            '--confirm',
            action='store_true',
            help='Confirm the reset operation'
        )
        parser.add_argument(
            '--keep-initial',
            action='store_true',
            help='Keep the initial migration file'
        )

    def handle(self, *args, **options):
        app_labels = options['app_labels']
        confirm = options['confirm']
        keep_initial = options['keep_initial']

        if not confirm:
            self.stdout.write(
                self.style.WARNING(
                    'This will delete migration files and reset the database!\\n'
                    'Use --confirm to proceed. This should only be used in development.'
                )
            )
            return

        # Validate apps exist
        for app_label in app_labels:
            try:
                apps.get_app_config(app_label)
            except LookupError:
                raise CommandError(f'App "{app_label}" not found')

        # Remove migration files
        for app_label in app_labels:
            app_config = apps.get_app_config(app_label)
            migrations_dir = os.path.join(app_config.path, 'migrations')
            
            if os.path.exists(migrations_dir):
                # Keep __init__.py and optionally 0001_initial.py
                for filename in os.listdir(migrations_dir):
                    if filename == '__init__.py':
                        continue
                    if keep_initial and filename.startswith('0001_initial'):
                        continue
                    if filename.endswith('.py'):
                        file_path = os.path.join(migrations_dir, filename)
                        os.remove(file_path)
                        self.stdout.write(f'Removed: {file_path}')

        # Remove migration records from database
        with connection.cursor() as cursor:
            for app_label in app_labels:
                cursor.execute(
                    "DELETE FROM django_migrations WHERE app = %s",
                    [app_label]
                )

        self.stdout.write(
            self.style.SUCCESS(
                f'Reset migrations for apps: {", ".join(app_labels)}\\n'
                'Run "python manage.py makemigrations" to create new migrations.'
            )
        )
''',

            f'{self.project_name}/management/commands/migrate_status.py': '''"""
Custom management command to show detailed migration status.
"""
from django.core.management.base import BaseCommand
from django.db import connection
from django.apps import apps
from django.db.migrations.loader import MigrationLoader
from django.db.migrations.recorder import MigrationRecorder
import os


class Command(BaseCommand):
    help = 'Show detailed migration status for all apps'

    def add_arguments(self, parser):
        parser.add_argument(
            '--app',
            type=str,
            help='Show status for specific app only'
        )
        parser.add_argument(
            '--verbose',
            action='store_true',
            help='Show verbose migration information'
        )

    def handle(self, *args, **options):
        app_filter = options.get('app')
        verbose = options['verbose']

        loader = MigrationLoader(connection)
        recorder = MigrationRecorder(connection)
        applied_migrations = recorder.applied_migrations()

        # Group migrations by app
        apps_migrations = {}
        for (app_label, migration_name), migration in loader.disk_migrations.items():
            if app_filter and app_label != app_filter:
                continue
                
            if app_label not in apps_migrations:
                apps_migrations[app_label] = []
            
            is_applied = (app_label, migration_name) in applied_migrations
            apps_migrations[app_label].append({
                'name': migration_name,
                'applied': is_applied,
                'migration': migration
            })

        # Display status
        for app_label, migrations in apps_migrations.items():
            self.stdout.write(
                self.style.HTTP_INFO(f'\\n{app_label}:')
            )
            
            if not migrations:
                self.stdout.write('  No migrations found')
                continue

            applied_count = sum(1 for m in migrations if m['applied'])
            total_count = len(migrations)
            
            self.stdout.write(
                f'  Status: {applied_count}/{total_count} applied'
            )

            for migration_info in migrations:
                status_icon = '✓' if migration_info['applied'] else '✗'
                status_color = self.style.SUCCESS if migration_info['applied'] else self.style.ERROR
                
                self.stdout.write(
                    f'  {status_color(status_icon)} {migration_info["name"]}'
                )
                
                if verbose:
                    migration = migration_info['migration']
                    dependencies = getattr(migration, 'dependencies', [])
                    operations = getattr(migration, 'operations', [])
                    
                    if dependencies:
                        self.stdout.write(f'    Dependencies: {dependencies}')
                    self.stdout.write(f'    Operations: {len(operations)}')

        # Show unapplied migrations summary
        unapplied_apps = []
        for app_label, migrations in apps_migrations.items():
            unapplied = [m for m in migrations if not m['applied']]
            if unapplied:
                unapplied_apps.append(f'{app_label} ({len(unapplied)})')

        if unapplied_apps:
            self.stdout.write(
                self.style.WARNING(
                    f'\\nUnapplied migrations in: {", ".join(unapplied_apps)}'
                )
            )
        else:
            self.stdout.write(
                self.style.SUCCESS('\\nAll migrations are up to date!')
            )
''',

            f'{self.project_name}/management/commands/generate_model_graph.py': '''"""
Custom management command to generate model relationship graph.
"""
from django.core.management.base import BaseCommand
from django.apps import apps
from django.db import models
import json


class Command(BaseCommand):
    help = 'Generate model relationship graph in various formats'

    def add_arguments(self, parser):
        parser.add_argument(
            '--format',
            choices=['json', 'dot', 'mermaid'],
            default='json',
            help='Output format for the graph'
        )
        parser.add_argument(
            '--output',
            type=str,
            help='Output file path'
        )
        parser.add_argument(
            '--app',
            type=str,
            help='Generate graph for specific app only'
        )

    def handle(self, *args, **options):
        output_format = options['format']
        output_file = options.get('output')
        app_filter = options.get('app')

        # Collect model information
        models_info = {}
        relationships = []

        for app_config in apps.get_app_configs():
            if app_filter and app_config.label != app_filter:
                continue

            for model in app_config.get_models():
                model_name = f'{app_config.label}.{model.__name__}'
                models_info[model_name] = {
                    'app': app_config.label,
                    'name': model.__name__,
                    'fields': [],
                    'relationships': []
                }

                # Analyze fields
                for field in model._meta.get_fields():
                    field_info = {
                        'name': field.name,
                        'type': field.__class__.__name__
                    }

                    if isinstance(field, models.ForeignKey):
                        related_model = f'{field.related_model._meta.app_label}.{field.related_model.__name__}'
                        relationships.append({
                            'from': model_name,
                            'to': related_model,
                            'type': 'ForeignKey',
                            'field': field.name
                        })
                        field_info['related_to'] = related_model

                    elif isinstance(field, models.ManyToManyField):
                        related_model = f'{field.related_model._meta.app_label}.{field.related_model.__name__}'
                        relationships.append({
                            'from': model_name,
                            'to': related_model,
                            'type': 'ManyToManyField',
                            'field': field.name
                        })
                        field_info['related_to'] = related_model

                    elif isinstance(field, models.OneToOneField):
                        related_model = f'{field.related_model._meta.app_label}.{field.related_model.__name__}'
                        relationships.append({
                            'from': model_name,
                            'to': related_model,
                            'type': 'OneToOneField',
                            'field': field.name
                        })
                        field_info['related_to'] = related_model

                    models_info[model_name]['fields'].append(field_info)

        # Generate output based on format
        if output_format == 'json':
            output = {
                'models': models_info,
                'relationships': relationships
            }
            content = json.dumps(output, indent=2)

        elif output_format == 'dot':
            content = self.generate_dot_graph(models_info, relationships)

        elif output_format == 'mermaid':
            content = self.generate_mermaid_graph(models_info, relationships)

        # Output to file or stdout
        if output_file:
            with open(output_file, 'w') as f:
                f.write(content)
            self.stdout.write(
                self.style.SUCCESS(f'Model graph saved to: {output_file}')
            )
        else:
            self.stdout.write(content)

    def generate_dot_graph(self, models_info, relationships):
        """Generate DOT format graph."""
        lines = ['digraph ModelGraph {']
        lines.append('  rankdir=LR;')
        lines.append('  node [shape=record];')

        # Add nodes
        for model_name, info in models_info.items():
            fields = '|'.join([f['name'] for f in info['fields'][:5]])  # Limit fields
            if len(info['fields']) > 5:
                fields += '|...'
            lines.append(f'  "{model_name}" [label="{{{info["name"]}|{fields}}}"];')

        # Add edges
        for rel in relationships:
            lines.append(f'  "{rel["from"]}" -> "{rel["to"]}" [label="{rel["type"]}"];')

        lines.append('}')
        return '\\n'.join(lines)

    def generate_mermaid_graph(self, models_info, relationships):
        """Generate Mermaid format graph."""
        lines = ['graph TD']

        # Add nodes
        for model_name, info in models_info.items():
            safe_name = model_name.replace('.', '_')
            lines.append(f'  {safe_name}[{info["name"]}]')

        # Add relationships
        for rel in relationships:
            from_safe = rel['from'].replace('.', '_')
            to_safe = rel['to'].replace('.', '_')
            rel_type = rel['type'].replace('Field', '')
            lines.append(f'  {from_safe} -->|{rel_type}| {to_safe}')

        return '\\n'.join(lines)
''',

            f'{self.project_name}/management/commands/db_backup.py': '''"""
Custom management command for database backup and restore.
"""
from django.core.management.base import BaseCommand, CommandError
from django.conf import settings
from django.db import connection
import subprocess
import os
from datetime import datetime
import gzip
import json


class Command(BaseCommand):
    help = 'Backup and restore database'

    def add_arguments(self, parser):
        subparsers = parser.add_subparsers(dest='action', help='Available actions')
        
        # Backup command
        backup_parser = subparsers.add_parser('backup', help='Create database backup')
        backup_parser.add_argument(
            '--output',
            type=str,
            help='Backup file path (default: auto-generated)'
        )
        backup_parser.add_argument(
            '--compress',
            action='store_true',
            help='Compress backup file'
        )
        backup_parser.add_argument(
            '--include-media',
            action='store_true',
            help='Include media files in backup'
        )

        # Restore command
        restore_parser = subparsers.add_parser('restore', help='Restore database from backup')
        restore_parser.add_argument(
            'backup_file',
            type=str,
            help='Backup file path'
        )
        restore_parser.add_argument(
            '--confirm',
            action='store_true',
            help='Confirm the restore operation'
        )

    def handle(self, *args, **options):
        action = options['action']
        
        if action == 'backup':
            self.handle_backup(options)
        elif action == 'restore':
            self.handle_restore(options)
        else:
            self.print_help('manage.py', 'db_backup')

    def handle_backup(self, options):
        """Handle database backup."""
        output_file = options.get('output')
        compress = options['compress']
        include_media = options['include_media']

        if not output_file:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = f'backup_{timestamp}.sql'
            if compress:
                output_file += '.gz'

        # Get database settings
        db_settings = settings.DATABASES['default']
        
        if db_settings['ENGINE'] == 'django.db.backends.postgresql':
            self.backup_postgresql(db_settings, output_file, compress)
        elif db_settings['ENGINE'] == 'django.db.backends.sqlite3':
            self.backup_sqlite(db_settings, output_file, compress)
        else:
            raise CommandError(f'Unsupported database engine: {db_settings["ENGINE"]}')

        # Backup media files if requested
        if include_media:
            self.backup_media(output_file)

        self.stdout.write(
            self.style.SUCCESS(f'Database backup created: {output_file}')
        )

    def backup_postgresql(self, db_settings, output_file, compress):
        """Backup PostgreSQL database."""
        cmd = [
            'pg_dump',
            '-h', db_settings['HOST'],
            '-p', str(db_settings['PORT']),
            '-U', db_settings['USER'],
            '-d', db_settings['NAME'],
            '--no-password'
        ]

        env = os.environ.copy()
        env['PGPASSWORD'] = db_settings['PASSWORD']

        if compress:
            with gzip.open(output_file, 'wt') as f:
                subprocess.run(cmd, stdout=f, env=env, check=True)
        else:
            with open(output_file, 'w') as f:
                subprocess.run(cmd, stdout=f, env=env, check=True)

    def backup_sqlite(self, db_settings, output_file, compress):
        """Backup SQLite database."""
        import shutil
        
        source_db = db_settings['NAME']
        
        if compress:
            with open(source_db, 'rb') as f_in:
                with gzip.open(output_file, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
        else:
            shutil.copy2(source_db, output_file)

    def backup_media(self, backup_file):
        """Backup media files."""
        media_root = getattr(settings, 'MEDIA_ROOT', None)
        if not media_root or not os.path.exists(media_root):
            return

        import tarfile
        
        media_backup = backup_file.replace('.sql', '_media.tar.gz')
        with tarfile.open(media_backup, 'w:gz') as tar:
            tar.add(media_root, arcname='media')

        self.stdout.write(f'Media backup created: {media_backup}')

    def handle_restore(self, options):
        """Handle database restore."""
        backup_file = options['backup_file']
        confirm = options['confirm']

        if not os.path.exists(backup_file):
            raise CommandError(f'Backup file not found: {backup_file}')

        if not confirm:
            self.stdout.write(
                self.style.WARNING(
                    'This will replace the current database!\\n'
                    'Use --confirm to proceed.'
                )
            )
            return

        # Get database settings
        db_settings = settings.DATABASES['default']
        
        if db_settings['ENGINE'] == 'django.db.backends.postgresql':
            self.restore_postgresql(db_settings, backup_file)
        elif db_settings['ENGINE'] == 'django.db.backends.sqlite3':
            self.restore_sqlite(db_settings, backup_file)
        else:
            raise CommandError(f'Unsupported database engine: {db_settings["ENGINE"]}')

        self.stdout.write(
            self.style.SUCCESS(f'Database restored from: {backup_file}')
        )

    def restore_postgresql(self, db_settings, backup_file):
        """Restore PostgreSQL database."""
        # Drop and recreate database
        drop_cmd = [
            'dropdb',
            '-h', db_settings['HOST'],
            '-p', str(db_settings['PORT']),
            '-U', db_settings['USER'],
            db_settings['NAME']
        ]

        create_cmd = [
            'createdb',
            '-h', db_settings['HOST'],
            '-p', str(db_settings['PORT']),
            '-U', db_settings['USER'],
            db_settings['NAME']
        ]

        restore_cmd = [
            'psql',
            '-h', db_settings['HOST'],
            '-p', str(db_settings['PORT']),
            '-U', db_settings['USER'],
            '-d', db_settings['NAME']
        ]

        env = os.environ.copy()
        env['PGPASSWORD'] = db_settings['PASSWORD']

        # Execute commands
        subprocess.run(drop_cmd, env=env, check=False)  # Don't fail if DB doesn't exist
        subprocess.run(create_cmd, env=env, check=True)

        if backup_file.endswith('.gz'):
            with gzip.open(backup_file, 'rt') as f:
                subprocess.run(restore_cmd, stdin=f, env=env, check=True)
        else:
            with open(backup_file, 'r') as f:
                subprocess.run(restore_cmd, stdin=f, env=env, check=True)

    def restore_sqlite(self, db_settings, backup_file):
        """Restore SQLite database."""
        import shutil
        
        target_db = db_settings['NAME']
        
        # Backup current database
        if os.path.exists(target_db):
            backup_current = f'{target_db}.backup'
            shutil.copy2(target_db, backup_current)
            self.stdout.write(f'Current database backed up to: {backup_current}')

        if backup_file.endswith('.gz'):
            with gzip.open(backup_file, 'rb') as f_in:
                with open(target_db, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
        else:
            shutil.copy2(backup_file, target_db)
'''
        }
    
    def create_enhanced_settings(self) -> Dict[str, str]:
        """Create enhanced Django settings with ORM optimizations."""
        
        return {
            f'{self.project_name}/settings/__init__.py': '',
            
            f'{self.project_name}/settings/base.py': '''"""
Base Django settings for enhanced ORM functionality.
"""
import os
from pathlib import Path
import environ

# Build paths
BASE_DIR = Path(__file__).resolve().parent.parent.parent

# Environment variables
env = environ.Env(
    DEBUG=(bool, False),
    USE_TZ=(bool, True),
    USE_I18N=(bool, True),
    USE_L10N=(bool, True),
)

# Read .env file
environ.Env.read_env(os.path.join(BASE_DIR, '.env'))

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = env('SECRET_KEY', default='django-insecure-change-me-in-production')

# Application definition
DJANGO_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
]

THIRD_PARTY_APPS = [
    'rest_framework',
    'corsheaders',
    'django_filters',
    'rest_framework_simplejwt',
    'django_extensions',
    'django_celery_beat',
    'django_celery_results',
]

LOCAL_APPS = [
    # Add your apps here
]

INSTALLED_APPS = DJANGO_APPS + THIRD_PARTY_APPS + LOCAL_APPS

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = '{{projectName}}.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [BASE_DIR / 'templates'],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = '{{projectName}}.wsgi.application'
ASGI_APPLICATION = '{{projectName}}.asgi.application'

# Database configuration with connection pooling
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': env('DB_NAME', default='{{projectName}}'),
        'USER': env('DB_USER', default='postgres'),
        'PASSWORD': env('DB_PASSWORD', default='password'),
        'HOST': env('DB_HOST', default='localhost'),
        'PORT': env('DB_PORT', default='5432'),
        'OPTIONS': {
            'MAX_CONNS': 20,
            'MIN_CONNS': 5,
        },
        'CONN_MAX_AGE': 600,  # Connection pooling
    }
}

# Enhanced database configuration for performance
DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Migration settings
MIGRATION_MODULES = {}

# Custom migration path for better organization
MIGRATION_PATH_TEMPLATE = 'migrations.{year}.{month}'

# Password validation
AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]

# Internationalization
LANGUAGE_CODE = env('LANGUAGE_CODE', default='en-us')
TIME_ZONE = env('TIME_ZONE', default='UTC')
USE_I18N = True
USE_L10N = True
USE_TZ = True

# Static files
STATIC_URL = '/static/'
STATIC_ROOT = BASE_DIR / 'staticfiles'
STATICFILES_DIRS = [
    BASE_DIR / 'static',
]

# Media files
MEDIA_URL = '/media/'
MEDIA_ROOT = BASE_DIR / 'media'

# Django REST Framework
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
        'rest_framework.authentication.SessionAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.LimitOffsetPagination',
    'PAGE_SIZE': 20,
    'DEFAULT_FILTER_BACKENDS': [
        'django_filters.rest_framework.DjangoFilterBackend',
        'rest_framework.filters.SearchFilter',
        'rest_framework.filters.OrderingFilter',
    ],
    'DEFAULT_THROTTLE_CLASSES': [
        'rest_framework.throttling.AnonRateThrottle',
        'rest_framework.throttling.UserRateThrottle'
    ],
    'DEFAULT_THROTTLE_RATES': {
        'anon': '100/hour',
        'user': '1000/hour'
    }
}

# JWT Configuration
from datetime import timedelta

SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(minutes=60),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': True,
    'BLACKLIST_AFTER_ROTATION': True,
}

# Celery Configuration
CELERY_BROKER_URL = env('CELERY_BROKER_URL', default='redis://localhost:6379/0')
CELERY_RESULT_BACKEND = env('CELERY_RESULT_BACKEND', default='redis://localhost:6379/0')
CELERY_ACCEPT_CONTENT = ['application/json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = TIME_ZONE

# Cache Configuration
CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.redis.RedisCache',
        'LOCATION': env('REDIS_URL', default='redis://localhost:6379/1'),
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
        },
        'KEY_PREFIX': '{{projectName}}',
        'TIMEOUT': 300,
        'VERSION': 1,
    }
}

# Session Configuration
SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
SESSION_CACHE_ALIAS = 'default'
SESSION_COOKIE_AGE = 86400  # 24 hours

# Logging Configuration
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {process:d} {thread:d} {message}',
            'style': '{',
        },
        'simple': {
            'format': '{levelname} {message}',
            'style': '{',
        },
    },
    'handlers': {
        'file': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': BASE_DIR / 'logs' / 'django.log',
            'maxBytes': 15728640,  # 15MB
            'backupCount': 10,
            'formatter': 'verbose',
        },
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'simple',
        },
    },
    'root': {
        'handlers': ['console', 'file'],
        'level': 'INFO',
    },
    'loggers': {
        'django': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False,
        },
        '{{projectName}}': {
            'handlers': ['console', 'file'],
            'level': 'DEBUG',
            'propagate': False,
        },
    },
}

# Custom ORM Settings
# Optimize database queries
DATABASE_QUERY_TIMEOUT = 30  # seconds
DATABASE_QUERY_LOG_THRESHOLD = 0.5  # Log slow queries

# Model settings
MODEL_VALIDATION_ENABLED = True
SOFT_DELETE_ENABLED = True

# Performance settings
DATABASE_CONN_HEALTH_CHECKS = True
CONN_HEALTH_CHECK_INTERVAL = 60  # seconds
''',

            f'{self.project_name}/settings/development.py': '''"""
Development settings with enhanced ORM debugging.
"""
from .base import *

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = True
ALLOWED_HOSTS = ['localhost', '127.0.0.1', '0.0.0.0']

# Database configuration for development
DATABASES['default'].update({
    'OPTIONS': {
        'MAX_CONNS': 5,  # Lower connection pool for development
        'MIN_CONNS': 1,
    }
})

# Add development-specific apps
INSTALLED_APPS += [
    'debug_toolbar',
    'django_extensions',
    'silk',  # SQL profiling
]

# Add debug toolbar middleware
MIDDLEWARE = [
    'debug_toolbar.middleware.DebugToolbarMiddleware',
    'silk.middleware.SilkyMiddleware',
] + MIDDLEWARE

# Debug toolbar configuration
INTERNAL_IPS = [
    '127.0.0.1',
    'localhost',
]

DEBUG_TOOLBAR_CONFIG = {
    'SHOW_TOOLBAR_CALLBACK': lambda request: DEBUG,
    'SHOW_TEMPLATE_CONTEXT': True,
}

# Enhanced logging for development
LOGGING['handlers']['console']['level'] = 'DEBUG'
LOGGING['loggers']['django.db.backends'] = {
    'handlers': ['console'],
    'level': 'DEBUG',
    'propagate': False,
}

# Silk configuration for SQL profiling
SILKY_PYTHON_PROFILER = True
SILKY_PYTHON_PROFILER_BINARY = True
SILKY_AUTHENTICATION = True
SILKY_AUTHORISATION = True
SILKY_PERMISSIONS = lambda user: user.is_superuser
SILKY_META = True

# Development-specific ORM settings
DATABASE_QUERY_LOG_THRESHOLD = 0.1  # Log all queries over 100ms
ENABLE_QUERY_DEBUGGING = True

# Email backend for development
EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'

# Static files for development
STATICFILES_DIRS += [
    BASE_DIR / 'dev_static',
]

# Development extensions
SHELL_PLUS = 'ipython'
SHELL_PLUS_PRINT_SQL = True
SHELL_PLUS_IMPORTS = [
    'from django.db import transaction',
    'from django.db.models import Q, F, Count, Sum, Avg',
    'from datetime import datetime, timedelta',
]

# Graph models command configuration
GRAPH_MODELS = {
    'all_applications': True,
    'group_models': True,
}
''',

            f'{self.project_name}/settings/production.py': '''"""
Production settings with ORM optimizations.
"""
from .base import *

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = False
ALLOWED_HOSTS = env.list('ALLOWED_HOSTS', default=[])

# Database optimizations for production
DATABASES['default'].update({
    'OPTIONS': {
        'MAX_CONNS': 50,  # Higher connection pool for production
        'MIN_CONNS': 10,
        'connect_timeout': 10,
        'options': '-c default_transaction_isolation=serializable'
    },
    'CONN_MAX_AGE': 0,  # Disable persistent connections in production with load balancer
})

# Security settings
SECURE_SSL_REDIRECT = env.bool('SECURE_SSL_REDIRECT', default=True)
SECURE_HSTS_SECONDS = env.int('SECURE_HSTS_SECONDS', default=31536000)
SECURE_HSTS_INCLUDE_SUBDOMAINS = True
SECURE_HSTS_PRELOAD = True
SECURE_CONTENT_TYPE_NOSNIFF = True
SECURE_BROWSER_XSS_FILTER = True
X_FRAME_OPTIONS = 'DENY'

# Production logging
LOGGING['handlers']['file']['filename'] = '/var/log/django/django.log'
LOGGING['handlers']['sql_file'] = {
    'level': 'WARNING',
    'class': 'logging.handlers.RotatingFileHandler',
    'filename': '/var/log/django/sql.log',
    'maxBytes': 52428800,  # 50MB
    'backupCount': 5,
    'formatter': 'verbose',
}

LOGGING['loggers']['django.db.backends'] = {
    'handlers': ['sql_file'],
    'level': 'WARNING',  # Only log slow/problematic queries
    'propagate': False,
}

# Production ORM settings
DATABASE_QUERY_TIMEOUT = 10  # Stricter timeout
DATABASE_QUERY_LOG_THRESHOLD = 1.0  # Log queries over 1 second
CONN_HEALTH_CHECK_INTERVAL = 30  # More frequent health checks

# Cache configuration for production
CACHES['default']['TIMEOUT'] = 3600  # 1 hour cache
CACHES['default']['OPTIONS']['CONNECTION_POOL_KWARGS'] = {
    'max_connections': 100,
    'retry_on_timeout': True,
}

# Session security
SESSION_COOKIE_SECURE = True
SESSION_COOKIE_HTTPONLY = True
SESSION_COOKIE_SAMESITE = 'Strict'
CSRF_COOKIE_SECURE = True
CSRF_COOKIE_HTTPONLY = True

# Static files for production
STATICFILES_STORAGE = 'django.contrib.staticfiles.storage.ManifestStaticFilesStorage'

# Media files for production (consider using cloud storage)
# DEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'
# AWS_STORAGE_BUCKET_NAME = env('AWS_STORAGE_BUCKET_NAME')
'''
        }